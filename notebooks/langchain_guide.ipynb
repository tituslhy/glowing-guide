{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12b20dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d35d7f",
   "metadata": {},
   "source": [
    "## Initializing an LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f0727e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "_ = load_dotenv(find_dotenv())\n",
    "llm = ChatOpenAI(model=\"gpt-5-nano\", temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04a6697",
   "metadata": {},
   "source": [
    "## Invocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e203e99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hi there! How can I help today? I can answer questions, explain concepts, help with writing or coding, brainstorm ideas, plan a project, summarize articles, or assist with many other tasks. Tell me what you’re working on or what you’d like to achieve. Here are some quick prompts if you’re not sure:\\n- Explain [topic]\\n- Help me write [text type]\\n- Debug this code\\n- Plan a trip or event\\n- Summarize this article\\n- Brainstorm ideas for [project]', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 307, 'prompt_tokens': 8, 'total_tokens': 315, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 192, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CUCLe1AGJDRySJPmYCwLHQfIY53Cd', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--563c7e80-bddc-4b68-849b-f1037a133b15-0', usage_metadata={'input_tokens': 8, 'output_tokens': 307, 'total_tokens': 315, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 192}})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"Hi!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976feff0",
   "metadata": {},
   "source": [
    "## Batch invocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15d1af99",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [\n",
    "    \"How can quantum computing be used together with generative AI to develop new algorithms for drug discovery?\",\n",
    "    \"How do you think we can save the world from climate change?\",\n",
    "    \"What are the ethical implications of using AI in healthcare?\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7266f3",
   "metadata": {},
   "source": [
    "The `batch` method allows us to send multiple questions concurrently - but the method will onyl return the output for the entire batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d388850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Short answer\\nQuantum computing can augment generative AI in drug discovery by (1) giving more accurate electronic-structure and property evaluations for candidate molecules, (2) enabling new optimization and search methods for designing molecules under complex constraints, and (3) letting quantum-informed representations and learning algorithms guide generation and prioritization. In practice, you typically run a hybrid workflow: a generative model proposes candidates, a quantum computer (or simulator) provides tighter physics-based scores or features for a subset of those candidates, and the results feedback to improve the generative model.\\n\\nWhat this looks like in practice\\n\\n1) Where quantum computing adds value\\n- Accurate quantum chemistry for property evaluation\\n  - Use quantum algorithms (VQE,, and in the longer term QPE on fault-tolerant hardware) to estimate ground-state energies, reaction barriers, excitation energies, and other properties with higher fidelity than many classical approximations.\\n  - This improves scoring/ranking of candidates beyond what empirical force fields and approximate DFT often provide, especially for rare or challenging chemical motifs.\\n\\n- Better handling of electronic structure in design\\n  - For heteroatoms, charge-transfer, and frontier orbital interactions that are important for binding and reactivity, quantum methods can capture effects that are hard for classical models to describe accurately.\\n  - Fragment-based quantum calculations can scale to larger drug-like molecules by combining high-accuracy quantum results on fragments with classical models.\\n\\n- Quantum-enabled optimization and search\\n  - QAOA (and related quantum optimization) can tackle combinatorial optimization tasks in drug design, such as multi-objective docking scores, synthetic feasibility, or conformer/fragment assembly under constraints.\\n  - Quantum-assisted global optimization can help navigate the enormous chemical space more efficiently than purely classical heuristics.\\n\\n- Quantum machine learning and quantum representations\\n  - Quantum kernels, quantum feature maps, or quantum neural networks can be used to learn representations of chemical spaces that encode physical constraints or electronic-structure information.\\n  - These quantum representations can condition generative models or be used in downstream ranking/policy networks to improve generation quality.\\n\\n2) How to combine with generative AI (typical workflows)\\n- Pipeline pattern: generate → evaluate with quantum chemistry → re-rank and refine → generate further\\n  - Step 1: Train a generative model (e.g., diffusion model, VAEs, or graph-based transformers) to propose drug-like molecules or fragments conditioned on a target (protein pocket, binding site features, or desired property profile).\\n  - Step 2: Use fast classical predictors to filter the bulk of candidates (drug-likeness, synthetic feasibility, basic ADMET).\\n  - Step 3: For a subset of high-potential candidates, run quantum-calibrated evaluations (VQE-like energy estimates, accurate reaction energies, or excitation properties, possibly in a QM/MM fragment-based approach).\\n  - Step 4: Incorporate the quantum-derived scores into the objective for retraining or fine-tuning the generative model (reinforcement learning with a quantum-informed reward, or multi-objective optimization).\\n  - Step 5: Iterate, with the generative model learning to propose designs that are both synthetically accessible and quantum-mechanically favorable.\\n\\n- Conditioning generative models on quantum features\\n  - Use quantum-derived molecular descriptors (e.g., partial charges, orbital energies, fragment energies) as conditioning inputs to the generator, or as features in the discriminator/critic in a conditional GAN/diffusion setup.\\n  - Train quantum-aware encodings that help the model respect physical constraints (electronic stability, conservation laws) during generation.\\n\\n- Quantum-enhanced scoring and ranking\\n  - Combine classical fast scores with a quantum score to form a composite objective.\\n  - Use the quantum score to re-rank top candidates from the generator, creating a tighter funnel into wet-lab testing.\\n\\n- Multi-resource optimization\\n  - Use quantum optimization to solve a constrained multi-objective problem: maximize binding potential and synthetic accessibility while minimizing toxicity and cost.\\n  - Integrate this into the generative loop so the model tends to propose molecules that are likelier to satisfy all objectives.\\n\\n3) Practical considerations and current state\\n- Hardware reality\\n  - Today’s quantum hardware is noisy and small-scale. Hybrid approaches (noise-aware VQE/quantum simulators, error mitigation, and fragment-based methods) are the norm.\\n  - Expect incremental gains in accuracy and constrained problem sizes rather than full-scale, routine ab initio drug screening on real hardware yet.\\n\\n- Software and tooling\\n  - Frameworks for hybrid quantum-classical workflows include Qiskit/IBM Nature, PennyLane (from XANADU), OpenFermion, and classical ML stacks (PyTorch, TensorFlow) integrated with chemical toolkits (RDKit, OpenFF).\\n  - Molecular generative models are well-developed (diffusion models, graph-based GNNs, transformers); the novelty is in integrating quantum-derived signals into training and scoring.\\n\\n- Data and evaluation\\n  - Use curated datasets for binding poses, activity data, and ADMET properties. Where possible, generate high-quality quantum-calculated descriptors for a representative set of molecules to guide the model.\\n  - Validate with held-out tests and, when feasible, prospective experimental validation.\\n\\n4) Example concrete research directions\\n- Quantum-calibrated diffusion models\\n  - Condition a diffusion model on quantum-derived features or use a quantum-scored objective to steer diffusion toward regions of chemical space with more favorable electronic properties.\\n\\n- Quantum-enhanced reinforcement learning for lead optimization\\n  - An RL agent proposes modifications to a scaffold; a quantum evaluator returns a high-fidelity score for the modified molecule, shaping the reward to prefer quantum-favorable designs.\\n\\n- Fragment QM/MM-guided docking and design\\n  - Use quantum methods on key fragments or functional groups to compute accurate interaction energies, feeding those into a ranking function for docked poses and fragment assembly.\\n\\n- Quantum-inspired representations for molecules\\n  - Use quantum-inspired kernels or tensor-network representations to learn compact, physics-aware embeddings that improve the efficiency or generalization of generative models.\\n\\n5) What a starter plan might look like\\n- Build a small hybrid pipeline\\n  - Pick a target (e.g., a well-studied protein pocket) and a set of candidate fragments/molecules.\\n  - Train a graph-based or diffusion-based generator on this space.\\n  - Implement a quantum evaluation module for a subset of top candidates (e.g., fragment-level energies, frontier orbital indicators, or small QM/MM calculations).\\n  - Create a simple reward/score that blends classical properties (synthetic feasibility, basic ADMET) with quantum-derived scores.\\n  - Iterate: retrain the generator with the quantum-informed rewards and evaluate on a held-out set.\\n\\n- Start with available tools\\n  - Use RDKit for chemistry handling, a standard molecule database for training data, and a hybrid quantum framework (e.g., PennyLane or Qiskit Nature) to run small VQE-like calculations on accessible molecules.\\n  Install a lightweight, fragment-based QM approach to keep computations tractable.\\n\\n- Build the team and plan\\n  - Roles: quantum chemists, ML/DA designers (generative models), software engineers for hybrid pipelines, and domain experts in pharmacology/toxicity.\\n  - Phased milestones: (1) establish a baseline generative model with classical scoring, (2) add a quantum scoring component for a small set of candidates, (3) close the loop with RL or fine-tuning, (4) pilot a few more complex targets or larger fragments.\\n\\nBottom line\\nQuantum computing can enhance generative AI-driven drug discovery by providing more accurate, physics-grounded evaluations of candidates and by enabling new optimization/search strategies in the design space. In practice, this means a hybrid workflow where a generator proposes molecules, a quantum calculator supplies tighter electronic-structure or optimization signals for a subset of designs, and these signals guide the next generation of candidates. While the field is still early and hardware-limited, it’s a promising direction for delivering smarter, more physically informed drug-design pipelines in the next few years. If you’d like, I can sketch a concrete, step-by-step plan tailored to your target protein, available hardware, and preferred AI framework.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 3663, 'prompt_tokens': 25, 'total_tokens': 3688, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 1984, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CUCNz3EFr4vBU2WUQB0qY6yoW7JDd', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--75beace7-8e2d-41ef-ae4d-255af8556a99-0' usage_metadata={'input_tokens': 25, 'output_tokens': 3663, 'total_tokens': 3688, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 1984}}\n",
      "content='Great question. There isn’t one magic fix, but there is a coherent set of actions that, if scaled fast enough and fairly, can substantially slow and eventually reverse the worst climate impacts. Here’s a practical, multi-layer plan you can think about—at the individual, community, business, and government levels.\\n\\nWhy this is possible (in brief)\\n- Clean energy costs have fallen dramatically; wind, solar, and batteries are cheaper than many fossil options in many places.\\n- Technology and policy tools exist to cut emissions quickly and create new jobs and markets.\\n- If done with equity and justice, the transition can improve health, energy security, and resilience.\\n\\nKey levers for saving the world from climate change\\n1) Electrify and decarbonize electricity\\n- Move to 100% low-emmission electricity where feasible: rapidly deploy wind, solar, hydro, and other clean sources; retire coal and reduce oil/gas use in power.\\n- Modernize the grid: smarter grids, more transmission lines, storage (batteries, pumped hydro), demand response, and better grid reliability.\\n- Safeguard reliability and affordability: diversified energy mix, reserves, and investment in resilience.\\n\\n2) Electrify transport and heat\\n- Transport: accelerate electric vehicles (cars, buses, trucks), expand charging networks, and invest in rail to shift freight and passenger travel off roads.\\n- Buildings and industry: switch buildings to electric heat pumps; use district heating where practical; electrify industrial processes where possible; push for high-efficiency appliances and heat recovery.\\n- Reduce methane and other non-CO2 emissions from fossil fuel systems (leaks from gas systems, enteric methane from ruminant animals, etc.).\\n\\n3) Clean up industry and heavy sectors\\n- Use electrification where feasible; otherwise switch to low-carbon fuels (green hydrogen, biomass) and energy-efficient processes.\\n- Invest in industrial decarbonization technologies: low-emission cement and steel, carbon capture, utilization, and storage (CCUS) where appropriate.\\n- Implement performance standards and incentives to push hardest-to-decarbonize sectors (cement, steel, chemicals) toward cleaner options.\\n\\n4) Protect and restore nature (nature-based solutions)\\n- Conserve and restore forests, peatlands, mangroves, and other ecosystems that store carbon.\\n- Improve agricultural practices to sequester carbon in soils, reduce nitrous oxide/ methane from farming, cut food waste.\\n- Implement smart land-use planning to balance food, energy, and nature.\\n\\n5) Remove CO2 from the atmosphere (as a supplement)\\n- Nature-based removal: large-scale forest and soil carbon management, restoring degraded ecosystems.\\n- Technology-based removal: direct air capture and other carbon engineering as a supplement to reduce excess atmospheric CO2 if needed.\\n- Ensure governance, transparency, and social consent for any large-scale removal projects.\\n\\n6) Finance, policy, and governance\\n- Put a price on carbon and/or implement strong performance standards; use revenue to fund clean energy and protect the vulnerable.\\n- Phase out fossil fuel subsidies and reallocate subsidies to clean alternatives.\\n- Use border-adjustment mechanisms where appropriate to prevent carbon leakage.\\n- Strengthen climate risk disclosure, align financial flows with low-carbon pathways, and scale climate finance for developing countries.\\n\\n7) Adaptation and resilience\\n- Build resilient infrastructure (flood defenses, water management, heat-resistant buildings).\\n- Plan for climate risks in cities and rural areas (extreme heat, drought, storms, sea‑level rise).\\n- Invest in early warning systems, emergency planning, and health system readiness.\\n\\n8) Equity, jobs, and a just transition\\n- Protect workers and communities dependent on fossil fuels with retraining, new jobs in clean energy, and fair transition plans.\\n- Ensure energy access and affordability for all, especially low-income households.\\n- Engage affected communities in planning and governance.\\n\\n9) Global cooperation and local action\\n- Global targets aligned with science (net-zero by around mid-century for many regions; trials for earlier action).\\n- Technology sharing, finance, and knowledge transfer to help all countries scale clean energy and resilience.\\n- Local action scales up: cities, states/provinces, and businesses can drive much of the decarbonization even before national policy fully aligns.\\n\\nWhat you can do right now (practical steps)\\n- Reduce personal energy and emissions: use less energy at home (insulation, efficient appliances), switch to clean electricity, drive or commute less by bike/public transit, if possible purchase an electric vehicle.\\n- Vote, advocate, and participate: support credible climate policies, hold leaders accountable, back businesses with transparent climate plans.\\n- Support and invest in clean energy projects and green technologies.\\n- Eat more plants and reduce food waste; support sustainable farming where you can.\\n- Help your community prepare for climate impacts (heat plans, flood defenses, disaster readiness).\\n\\nIf you want, I can tailor this into a concrete plan for a specific country, city, or sector (for example: “What would a 2030 plan look like for [your city]?” or “What policies would most cut emissions in the manufacturing sector?”). I can also translate these ideas into a timeline with milestones (2030, 2040, 2050) and a rough budget outline.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 2737, 'prompt_tokens': 19, 'total_tokens': 2756, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 1664, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CUCO0YL72l1H9ChEVfs65Ksttry1Y', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--374b0550-f641-4a48-a014-5efa460c9ce9-0' usage_metadata={'input_tokens': 19, 'output_tokens': 2737, 'total_tokens': 2756, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 1664}}\n",
      "content='AI in healthcare promises benefits like faster diagnosis, personalized treatment, and better use of scarce resources. But it also raises a range of ethical issues that need careful attention. Here’s a structured overview.\\n\\nKey ethical concerns\\n\\n- Safety, efficacy, and nonmaleficence\\n  - AI systems must be accurate, reliable, and appropriate for the contexts in which they’re used.\\n  - There is a risk of harm from erroneous outputs, overreliance (automation bias), or system failures in high-stakes settings.\\n\\n- Fairness, bias, and justice\\n  - Training data may reflect historical inequities or underrepresent certain populations, leading to poorer performance for those groups.\\n  - There is a risk that AI could exacerbate health disparities or unjustly allocate resources.\\n\\n- Privacy, data governance, and consent\\n  - AI relies on large amounts of patient data, raising concerns about privacy, data ownership, consent for use, and potential re-identification risks.\\n  - Data sharing across institutions can improve models but must be managed to protect individuals’ rights.\\n\\n- Autonomy, consent, and patient rights\\n  - Patients should understand when AI is involved in their care and have choices about how their data are used.\\n  - The use of AI decisions should not undermine patient autonomy or overwhelm patients with opaque processes.\\n\\n- Transparency, explainability, and trust\\n  - Many AI systems are “black boxes.” Clinicians and patients may demand explanations for AI recommendations.\\n  - Lack of transparency can undermine trust and hinder accountability.\\n\\n- Accountability and liability\\n  - Who is responsible for AI-driven decisions that cause harm? The developers, clinicians who used the tool, or the institution that deployed it?\\n  - How should accountability be allocated when models evolve after deployment through updates?\\n\\n- Impact on professional roles and the doctor–patient relationship\\n  - AI can change how clinicians work, potentially supporting or undermining clinical judgment.\\n  - There’s concern about deskilling, dependency, and the erosion of trust if patients feel decisions are delegated to machines.\\n\\n- Justice in access and global equity\\n  - Benefiting from AI should not be limited to well-funded settings; unequal access could widen global health disparities.\\n  - Costs of AI tools (licensing, infrastructure) may affect which patients receive benefits.\\n\\nFrameworks and practical guidance\\n\\n- Ethical principles to apply\\n  - Autonomy: respect patient choices and provide clear information about AI involvement.\\n  - Beneficence and nonmaleficence: aim to maximize benefit while minimizing harm.\\n  - Justice: ensure fair access, avoid bias, and distribute benefits and burdens equitably.\\n  - Transparency: provide understandable information about how AI contributes to decisions.\\n\\n- Governance and oversight\\n  - Establish ethics review and ongoing monitoring for AI tools (pre-deployment risk assessment and post-deployment surveillance).\\n  - Create clear accountability maps (who is responsible for design, validation, deployment, and remediation).\\n\\n- Data stewardship and privacy\\n  - Use data minimization, robust de-identification, and privacy-preserving techniques (e.g., federated learning, differential privacy) where possible.\\n  - Obtain appropriate consent for data use and be transparent about data provenance and purposes.\\n\\n- Bias detection and fairness\\n  - Audit models for performance across demographic groups and clinical subpopulations.\\n  - Plan remediation strategies for identified biases and continuously monitor for distributional shifts.\\n\\n- Explainability and clinical integration\\n  - Prefer interpretable or partially interpretable models in high-stakes contexts when possible, or provide robust explanations and confidence measures.\\n  - Ensure AI supports clinicians (decision aid) rather than replacing clinical judgment.\\n\\n- Regulation and standards\\n  - Comply with relevant medical-device and data-protection regulations (e.g., FDA pathways for software as a medical device, GDPR/ HIPAA in many jurisdictions).\\n  - Support or participate in standard-setting efforts for interoperability, safety, and fairness.\\n\\n- Patient-centered implementation\\n  - Involve diverse patient populations in design and testing.\\n  - Provide patient-facing explanations about how AI contributes to care and what choices exist.\\n\\nExamples of ethical tensions in practice\\n\\n- Radiology AI that detects cancers with high sensitivity but varying performance across ethnic groups could improve detection overall yet worsen outcomes for underrepresented groups not well captured in training data.\\n- A hospital uses an AI triage tool to allocate ICU beds. If the model’s predictions reflect historical biases (e.g., privileging certain illnesses over others), it could perpetuate injustice unless carefully audited and safeguarded.\\n- An AI chatbot used for triaging symptoms improves access for some patients but collects sensitive information; patients should know what data are stored and who may access them.\\n\\nWhat you can do as a clinician, developer, or leader\\n\\n- Build a clear governance structure that assigns responsibility and accountability for AI systems.\\n- Conduct bias and safety risk assessments early and throughout the system’s life cycle.\\n- Prioritize data stewardship: obtain meaningful consent, protect privacy, and use privacy-enhancing technologies where feasible.\\n- Prefer transparent, interpretable AI when possible; provide clinicians with explanations and confidence estimates.\\n- Maintain human oversight: use AI as a decision-support tool rather than a wholesale replacement for clinical judgment.\\n- Plan for post-deployment monitoring: track performance, report incidents, and have a remediation pathway for model updates.\\n- Engage patients and diverse stakeholders in the design, testing, and governance processes.\\n- Stay informed about regulatory changes and participate in peer-reviewed validation when possible.\\n\\nIf you’d like, tell me your specific focus (e.g., bias in imaging AI, regulatory requirements in a particular country, or how to implement an ethical review for an AI tool in your clinic), and I can tailor the guidance.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 2370, 'prompt_tokens': 17, 'total_tokens': 2387, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 1216, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CUCO0dDNENfM21NIW8W4Hv1z9Mqht', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--8d89395f-ee4d-48eb-b78d-b5a75cc32811-0' usage_metadata={'input_tokens': 17, 'output_tokens': 2370, 'total_tokens': 2387, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 1216}}\n"
     ]
    }
   ],
   "source": [
    "responses = llm.batch(questions)\n",
    "for response in responses:\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a122321d",
   "metadata": {},
   "source": [
    "The alternative is to use the `batch_as_completed` method to receive the output for each inddividual input as it finishes generating\n",
    "> The results might arrive out of order - it really depends on which finishes first!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38020ba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, AIMessage(content='Great question. Saving the world from climate change isn’t a single fix—it requires a fast, large-scale transformation across energy, industry, transport, land use, and finance, plus protection for people and ecosystems. Here’s a practical, evidence-based blueprint you can use or share.\\n\\nCore idea\\n- Reduce greenhouse gas emissions fast.\\n- Replace fossil energy with clean energy.\\n- Remove barriers to rapid decarbonization and fund a just transition.\\n- Adapt to the changes we can’t avoid and protect the most vulnerable.\\n\\nWhat decarbonization would look like (high level)\\n- Energy: Move to clean electricity (mostly wind, solar, plus storage and grid upgrades). Phase out new fossil-fuel electricity plants as quickly as feasible; retire the oldest, dirtiest plants first.\\n- Buildings: Electrify heating and cooling where possible (heat pumps), improve insulation and efficiency, and install smart energy systems.\\n- Transportation: Electrify light-duty vehicles, scale up clean public transit, promote biking/walking, and shift freight to efficient electric or low-carbon modes.\\n- Industry: Electrify and substitute low-carbon fuels where possible; deploy bestAvailableTech, energy efficiency, material recycling, and, where needed, carbon capture and storage (CCS) for hard-to-abate processes.\\n- Land and nature: Protect forests, restore wetlands and degraded lands, expand regenerative agriculture, and use nature-based solutions to sequester carbon and reduce climate risks.\\n- Finance and policy: Implement carbon pricing or equivalent regulations, shift subsidies away from fossil fuels, invest in clean tech, and ensure a just transition for workers and communities.\\n- Adaptation and resilience: Build resilient infrastructure, improve early-warning systems, and prepare for floods, droughts, heat, and sea-level rise.\\n\\nActions by sector and actor (practical steps)\\n- For individuals\\n  - Use clean electricity and energy-efficient appliances; insulate homes; consider heat pumps where feasible.\\n  - Prefer electric transport (EVs, public transit, biking) and reduce air travel when possible.\\n  - Eat less meat and dairy, and minimize food waste.\\n  - Support climate-friendly policies and divest from fossil-fuel-intensive options when you can.\\n- For communities and cities\\n  - Invest in renewable energy projects, grid upgrades, and energy retrofits for public buildings.\\n  - Build or expand safe, affordable public transit and bike-friendly infrastructure.\\n  - Protect and restore urban greenspaces; plan for heatwaves and flood risks.\\n- For businesses and employers\\n  - Set and publish science-based emissions targets; measure and reduce Scope 1–3 emissions.\\n  - Electrify operations, improve energy efficiency, and switch to renewable power.\\n  - Build resilient supply chains, upcycle materials, and adopt circular economy practices.\\n  - Use internal carbon pricing to guide investment decisions.\\n- For governments and policymakers\\n  - Put a credible plan to net-zero by mid-century with concrete interim targets (e.g., 2030 milestones).\\n  - Implement clear, predictable policies: carbon pricing or strong regulations, phase-out of new unabated fossil fuel projects, and subsidies redirected toward clean energy and efficiency.\\n  - Invest in grid modernization, storage, and R&D; fund climate-resilient infrastructure and adaptation.\\n  - Support a just transition: training and economic help for workers and communities affected by the shift away from fossil fuels.\\n  - Strengthen international cooperation, finance for developing countries, and technology transfer.\\n- For finance and international institutions\\n  - Align portfolios with net-zero trajectories; require climate risk disclosures.\\n  - Scale up climate finance for clean energy, adaptation, and loss and damage support.\\n  - Encourage private sector investment in low-carbon technologies and infrastructure.\\n\\nWhy this is feasible (and urgent)\\n- The technology is largely available now: renewables, energy efficiency, electric transport, and modern grid tech can cut emissions dramatically.\\n- The economics are increasingly favorable: clean energy and efficiency often cheaper on a life-cycle basis than fossil fuels; rapid cost declines continue.\\n- The challenge is political will, financing, and an equitable transition. Acting fast buys us time to reduce risks and costs.\\n\\nA simple, temporary metric to track progress\\n- Net zero by around 2050 with a steep reduction in emissions by at least 40-50% by 2030 (relative to a recent baseline).\\n- Large-scale deployment of clean electricity, efficient buildings, and electric transport by 2030–2035.\\n- Significant investment in nature-based solutions and adaptation measures to reduce vulnerability.\\n\\nWant a tailored plan?\\nIf you tell me your country, city, or sector (e.g., electricity, transport, manufacturing, agriculture), I can draft a concrete, prioritized action plan with near-term milestones, policy ideas, and a simple budget outline.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 2763, 'prompt_tokens': 19, 'total_tokens': 2782, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 1792, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CUCPvu5wBMvaQfMkTNmKUhPRp83D1', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--edf3b9fa-8eaf-451f-a192-a00dc5071452-0', usage_metadata={'input_tokens': 19, 'output_tokens': 2763, 'total_tokens': 2782, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 1792}}))\n",
      "(2, AIMessage(content='AI in healthcare offers real benefits (earlier diagnosis, personalized insights, efficiency) but also raises important ethical questions. Here’s a structured overview of the main issues, with notes on practical mitigation.\\n\\nCore ethical principles at stake\\n- Beneficence and non-maleficence: AI should improve patient outcomes and not cause avoidable harm.\\n- Autonomy and informed consent: patients should understand when AI is involved in their care and have meaningful choices about data use and treatment.\\n- Justice and fairness: benefits should be distributed equitably; avoid exacerbating health disparities.\\n- Privacy and confidentiality: protect sensitive health data used to train and run AI systems.\\n- Transparency and explainability: patients and clinicians may need understandable reasons for AI-driven recommendations.\\n- Accountability and responsibility: clarity about who is responsible for AI-driven decisions and their outcomes.\\n- Professional integrity and human oversight: clinicians remain responsible for care and should retain the ability to challenge or override AI when appropriate.\\n\\nKey ethical concerns\\n\\n1) Safety, efficacy, and reliability\\n- AI systems may not generalize beyond their training data; performance can degrade in new settings or populations.\\n- Risk of over-reliance by clinicians or automation bias, where users trust AI outputs over their own judgment.\\n- Challenge of validating complex models in real-world clinical workflows.\\n\\n2) Bias, fairness, and discrimination\\n- Training data may underrepresent certain groups (e.g., minority ethnic groups, the elderly, rural populations), leading to poorer accuracy for those patients.\\n- Potential for biased outcomes in diagnostics, prognostics, or risk scoring that worsen disparities.\\n\\n3) Transparency, explainability, and trust\\n- Many AI models (e.g., deep learning) are opaque, making it hard to explain to patients why a recommendation was made.\\n- Clinicians may struggle to interpret or contest AI outputs, impacting trust and shared decision-making.\\n\\n4) Privacy, data ownership, and consent\\n- Health data used to train and operate AI is highly sensitive; risk of re-identification or misuse.\\n- Questions about who owns patient data, who can access it, and whether patients can opt out of data use beyond their direct care.\\n\\n5) Accountability and liability\\n- If an AI-assisted decision harms a patient, who is legally responsible—the clinician, the institution, the AI vendor, or the developers?\\n- Need for clear governance, liability frameworks, and post-market monitoring.\\n\\n6)Autonomy and the patient-clinician relationship\\n- AI could shift decision-making power, potentially diminishing patient agency if care becomes overly automated.\\n- Clinician workload pressures and workflow changes may affect patient interaction.\\n\\n7) Access, equity, and global impact\\n- High-resource settings may benefit more quickly from AI tools; risk of widening gaps between well-funded and under-resourced systems.\\n- In low-resource settings, AI could improve access but must be appropriate for local conditions and evolving regulatory norms.\\n\\n8) Data governance and security\\n- Data sharing for AI development increases exposure to cybersecurity risks and potential data misuse.\\n- Need for robust safeguards against data breaches and adversarial attacks that could manipulate outputs.\\n\\n9) Economic and environmental considerations\\n- Costs of development, deployment, maintenance, and vendor lock-in.\\n- Environmental impact of training large models and running intensive computations.\\n\\nMitigation strategies and best practices\\n\\n- Put people first: design with clinicians and patients in mind; use human-in-the-loop approaches where appropriate.\\n- Rigorous validation: require external, diverse, real-world validation studies; test across settings and populations.\\n- Fairness-by-design: collect diverse training data, monitor performance across subgroups, and implement bias mitigation techniques.\\n- Explainability tailored to users: present actionable, understandable rationales where possible; provide confidence metrics and limitations.\\n- Data governance: obtain informed consent for data use, minimize data collection, anonymize where feasible, and employ privacy-preserving techniques (e.g., differential privacy, federated learning).\\n- Privacy and security: strong data protections, encryption, access controls, and ongoing security testing.\\n- Regulatory and ethical oversight: align with regulatory pathways (e.g., regulatory clearance for SaMD in the US/EU), ethics review, and ongoing post-market surveillance.\\n- Accountability frameworks: clearly define roles and responsibilities; establish incident reporting and remediation processes.\\n- Continuous monitoring and updates: track model drift, performance over time, and mechanism to retrain or retire models as needed.\\n- Workforce considerations: training for clinicians on AI tools, preserving essential clinical skills, and addressing potential job displacement concerns.\\n- Equitable access: ensure deployment plans consider diverse settings, not just high-resource environments; subsidize or adapt tools for underserved communities.\\n- Transparent governance: publish information about data sources, model limitations, intended use cases, and cosmethics (data provenance, bias tests, performance metrics).\\n\\nRegulatory and governance landscape (high level)\\n- In many regions, AI medical devices fall under “software as a medical device” (SaMD) rules; explicit risk-based classifications and post-market requirements apply.\\n- Emerging frameworks emphasize transparency, accountability, data rights, and safety monitoring.\\n- Privacy laws (e.g., GDPR, HIPAA) govern data handling; regulators increasingly scrutinize AI-specific risks like bias and explainability.\\n- International variation exists; organizations should engage with local regulators and ethics boards early.\\n\\nDomains where ethical issues are especially salient\\n- Imaging (radiology, pathology): risk of misdiagnosis if models misinterpret images or underperform on diverse populations.\\n- Dermatology and ophthalmology: bias due to skin tone diversity or imaging quality.\\n- Predictive analytics (sepsis risk, readmission, mortality): concerns about how risk scores influence care decisions and resource allocation.\\n- Genomics and personalized medicine: privacy concerns around genetic data and potential discrimination.\\n- Robot-assisted or automated interventions: questions about safety margins and accountability for automated behaviors.\\n\\nPractical checklist for organizations implementing AI in healthcare\\n- Define value and boundaries: specify intended use, who is the end user, and where human oversight remains.\\n- Ensure data diversity and quality: audit datasets for representation; document data provenance.\\n- Plan for fairness and bias mitigation: metrics, triggers for intervention, and ongoing audits.\\n- Build explainability into the design: user-friendly explanations suitable for clinicians and patients.\\n- Establish governance and accountability: roles, liability, and escalation paths.\\n- Implement strong privacy and security controls: data minimization, encryption, access controls, and incident response.\\n- Pilot and validate externally: conduct multi-site trials and real-world evaluations before broad rollout.\\n- Monitor post-deployment: track performance, drift, adverse events, and patient outcomes; have a retraining or decommission plan.\\n- Engage stakeholders: involve patients, clinicians, ethicists, and regulators from the start.\\n- Provide education and support: training for clinicians; clear patient information materials.\\n\\nIf you’d like, I can tailor this to a specific domain (e.g., radiology AI in a hospital setting, a dermatology AI tool, or a regulatory-compliance plan) and outline concrete steps, risk assessments, and governance structures.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 2707, 'prompt_tokens': 17, 'total_tokens': 2724, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 1280, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CUCPuMr331jLztNHEavcA89jfo99Z', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--5dea8e54-3bcc-49d4-b98e-09f011ee3a4f-0', usage_metadata={'input_tokens': 17, 'output_tokens': 2707, 'total_tokens': 2724, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 1280}}))\n",
      "(0, AIMessage(content='Summary\\nQuantum computing can complement generative AI in drug discovery by (a) enabling more accurate or faster evaluation of molecular properties and interactions, (b) providing new ways to represent and sample chemical space with quantum-powered models, and (c) offering quantum-augmented optimization for assembling desirable fragments or conformations. In practice, most proposals today are hybrid: a classical generative model proposes candidate molecules or scaffolds, a quantum component provides a high-fidelity evaluation or a quantum-enabled subroutine, and the feedback loop updates the generator.\\n\\nCommon ways they can work together\\n\\n1) Quantum-augmented property evaluation\\n- Use quantum chemistry on quantum hardware (or high-quality quantum simulators) to estimate properties that matter for drug design with higher accuracy than some classical approximations:\\n  - Binding energies or protein–ligand interaction energies\\n  - Reaction energetics and barriers for synthesis planning\\n  - Molecular electronic properties (HOMO/LUMO gaps, dipole moments) that correlate with pharmacokinetics\\n- Feed these quantum-derived properties into a generative model’s objective (e.g., reward or loss) to steer the generator toward molecules with more realistic or desirable energetics.\\n- Benefit: better scoring of candidates, potentially reducing false positives early in the design cycle.\\n\\n2) Quantum-enhanced generative models\\n- Replace or augment parts of a generative model with quantum components:\\n  - Quantum variational autoencoders (QVAEs) or quantum GANs (QGANs) to model complex distributions over molecular graphs or SMILES/digraph representations.\\n  - Quantum-inspired or hybrid quantum-classical graph neural networks to learn latent spaces that capture subtle correlations in chemical data.\\n- Goal: capture richer dependencies in chemical space or sample diverse, high-quality candidates more efficiently than purely classical models.\\n\\n3) Quantum-assisted optimization of discrete design choices\\n- Drug design often involves selecting fragments, ring systems, or substituents to optimize properties and fit a binding pocket.\\n- Use quantum optimization (e.g., QAOA or quantum annealing) to solve combinatorial problems in fragment screening, scaffold hopping, or docking pose selection that are hard for classical solvers.\\n- Benefit: potentially faster or more effective exploration of discrete design spaces and better Pareto front solutions for multi-property trade-offs.\\n\\n4) Quantum-enabled sampling and uncertainty\\n- Quantum devices can be used to sample from complex distributions that are hard to sample classically, which can improve:\\n  - Diversity of generated molecules\\n  - Exploration of rare but promising chemotypes\\n- Quantum kernels or quantum-inspired sampling can enrich uncertainty quantification, helping to decide which candidates to test experimentally.\\n\\n5) End-to-end differentiable hybrid pipelines\\n- In principle, you can build differentiable loops where a quantum circuit acts as a differentiable component in the evaluation of a candidate, and gradients flow back to the generative model.\\n- This is more mature in simulation or with low-depth quantum circuits; in practice it’s an area of active research due to noise and hardware limitations, but it’s a promising long-term direction.\\n\\nConcrete workflow patterns\\n\\nA. Hybrid loop: Generative model + quantum evaluation + feedback\\n- Step 1: Train a classical generative model (e.g., graph-based VAE or diffusion model) on known drug-like molecules.\\n- Step 2: The generator proposes a batch of candidate molecules.\\n- Step 3: A quantum chemistry engine (on simulators or hardware) evaluates high-value properties (e.g., binding energy estimates, reaction barriers, accurate pKa, etc.).\\n- Step 4: Combine quantum properties with classical properties (synthetic accessibility, ADMET) to form a multi-objective score.\\n- Step 5: Use the score to fine-tune the generator (reinforcement learning or supervised fine-tuning) and iterate.\\n\\nB. Quantum-enhanced generative model\\n- Step 1: Train a QGAN or QVAE on a dataset of molecules to learn a quantum-enhanced latent space.\\n- Step 2: Sample from the quantum model to generate candidates, then filter or refine with classical post-processing and fast classical property predictors.\\n- Step 3: Use high-fidelity quantum evaluations for top candidates to guide further training or selection.\\n\\nC. Quantum optimization in fragment-assembly\\n- Step 1: Represent candidate fragments and linkers as a combinatorial problem (which fragments to connect, how to arrange rings, etc.).\\n- Step 2: Solve with a quantum optimizer to maximize a multi-property objective (binding propensity, synthetic feasibility, etc.).\\n- Step 3: Take the optimized structure and run classical property estimation and experimental validation.\\n\\nKey quantum technologies and concepts involved\\n\\n- Quantum chemistry on hardware: VQE (Variational Quantum Eigensolver) for energy estimates; potential use of quantum phase estimation (QPE) as hardware improves.\\n- Quantum optimization: QAOA (Quantum Approximate Optimization Algorithm) or quantum annealing for discrete design problems (fragment selection, scaffold hopping).\\n- Quantum machine learning: quantum neural networks, quantum variational circuits, quantum autoencoders, quantum diffusion-like methods, and quantum kernels for molecular similarity.\\n- Quantum-assisted sampling: sampling from Boltzmann-like or other complex distributions to enrich chemical space exploration.\\n- Quantum-inspired methods: classical algorithms motivated by quantum ideas (tensor networks, low-rank approximations, or sampling heuristics) that can be run on conventional hardware with improvements.\\n\\nPractical considerations and challenges\\n\\n- Hardware maturity: Current quantum devices are noisy and have limited qubit counts, which constrains the size of molecules that can be studied directly. Often, quantum methods are used for small test molecules or as subroutines within a larger hybrid workflow.\\n- Error and noise management: Error mitigation and robust circuit design are essential to obtain trustworthy property estimates.\\n- Integration complexity: Building a seamless loop between generative models, quantum evaluators, and downstream experimental validation requires careful software engineering and data standards.\\n- Data quality and transfer: Quantum evaluations depend on accurate Hamiltonians and models; translating chemical intuition to quantum-ready representations and back can be nontrivial.\\n- Validation burden: The ultimate proof is experimental validation; quantum-augmented predictions must translate to real-world improvements in hit rate and time-to-lead.\\n\\nWhat a path forward might look like for a research or development team\\n\\n- Start with a focused bottleneck: pick one hard subproblem where quantum methods are most likely to help soon, such as high-fidelity binding energy estimates for a target of interest.\\n- Build a hybrid loop: train a strong classical generator, add a quantum evaluator for the bottleneck property, and use the results to rebalance the generator’s objective.\\n- Use quantum-inspired baselines: implement quantum-inspired optimization or sampling to establish baselines and understand potential gains before deploying real quantum hardware.\\n- Develop multi-fidelity strategies: combine cheap classical approximations with occasional quantum evaluations to calibrate and improve the classical models (active learning).\\n- Invest in tooling for integration: ensure data standards, experiment tracking, and interfaces between chemistry engines, ML models, and hardware simulators are robust.\\n\\nBottom line\\nGenerative AI excels at exploring vast chemical spaces and proposing diverse, plausible molecules, while quantum computing promises more accurate or efficient evaluation of key molecular properties and challenging optimization problems. By creating hybrid workflows that let a generator propose candidates and a quantum component provide high-fidelity assessments (and possibly perform discrete optimization or advanced sampling), you can potentially achieve faster discovery cycles, better-quality leads, and more reliable uncertainty quantification. Realizing these gains will require continued advances in quantum hardware, error mitigation, and integration with classical ML pipelines, but the combination is a natural and promising direction for next-generation drug-discovery algorithms.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 3548, 'prompt_tokens': 25, 'total_tokens': 3573, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 1984, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CUCPuXL7yviyxzt15uaBZi0abzarJ', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--bb8b70bd-1349-496d-be77-968b9ead394b-0', usage_metadata={'input_tokens': 25, 'output_tokens': 3548, 'total_tokens': 3573, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 1984}}))\n"
     ]
    }
   ],
   "source": [
    "for response in llm.batch_as_completed(questions):\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760d771d",
   "metadata": {},
   "source": [
    "### Reasoning \n",
    "This is one of the most amazing features that is now available!\n",
    "\n",
    "> But first we're going to use a `RateLimiter` to prevent our budget from exploding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d2180a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.rate_limiters import InMemoryRateLimiter\n",
    "\n",
    "rate_limiter = InMemoryRateLimiter(\n",
    "    requests_per_second = 0.1, # 1 request every 10 seconds\n",
    "    check_every_n_seconds=0.1, # check every 0.1 seconds whether the model is allowed to make a request\n",
    "    max_bucket_size=10, # allow bursting up to 10 requests at any time\n",
    ")\n",
    "\n",
    "reasoning = {\n",
    "    \"effort\": \"medium\",\n",
    "    \"summary\": \"auto\"\n",
    "}\n",
    "\n",
    "rate_limited_llm = ChatOpenAI(\n",
    "    model=\"gpt-5-nano\",\n",
    "    temperature=0,\n",
    "    reasoning = reasoning,\n",
    "    rate_limiter=rate_limiter,\n",
    ")\n",
    "\n",
    "## The non-streaming approach\n",
    "response = rate_limited_llm.invoke(questions[0])\n",
    "reasoning_steps = [b for b in response.content_blocks if b[\"type\"] == \"reasoning\"]\n",
    "print(\" \".join(step[\"reasoning\"] for step in reasoning_steps))\n",
    "\n",
    "## The streaming approach\n",
    "# for chunk in llm.stream(questions[0]):\n",
    "#     reasoning_steps = [r for r in chunk.content_blocks if r[\"type\"] == \"reasoning\"]\n",
    "#     print(reasoning_steps if reasoning_steps else chunk.text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65915a7",
   "metadata": {},
   "source": [
    "But we're using gpt-5-nano which is already [very affordable](https://openai.com/api/pricing/) at $0.05 per million input tokens and $0.40 per million output tokens.\n",
    "> We can afford to use it without a rate limiter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37eb1d48",
   "metadata": {},
   "source": [
    "### Custom run with configs and callback handlers!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d901c1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.callbacks import (\n",
    "    BaseCallbackHandler,\n",
    "    UsageMetadataCallbackHandler,\n",
    ")\n",
    "from langchain_core.utils import print_text\n",
    "\n",
    "class GreenStdOutCallbackHandler(BaseCallbackHandler):\n",
    "    \"\"\"A custom callback handler that prints the final output in green.\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def on_llm_end(self, response, **kwargs):\n",
    "        final_text = response.generations[0][0].text\n",
    "        print_text(final_text, color=\"green\")\n",
    "\n",
    "usage_callback = UsageMetadataCallbackHandler()\n",
    "stdout_callback = GreenStdOutCallbackHandler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6e1dd450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mThere are many ethical implications to consider when applying AI in healthcare. Here is a structured overview of the main issues, why they matter, and how they can be addressed.\n",
      "\n",
      "Key ethical principles at stake\n",
      "- Beneficence and non-maleficence: AI should improve health outcomes and not cause harm. Risks include misdiagnosis, inappropriate treatments, over-reliance on flawed models, and new kinds of errors.\n",
      "- Autonomy and informed consent: Patients should understand how AI is used in their care and still retain control over decisions about their treatment.\n",
      "- Justice and fairness: AI must not exacerbate health disparities or unfairly disadvantage specific populations (e.g., by race, gender, age, socioeconomic status).\n",
      "- Privacy and confidentiality: Patient data used to train and operate AI must be protected from unauthorized access and misuse.\n",
      "- Accountability: There must be clear responsibility for AI-driven decisions and outcomes (developers, clinicians, healthcare organizations, or regulators).\n",
      "\n",
      "Important ethical issues and considerations\n",
      "1) Data quality, representativeness, and bias\n",
      "- Training data may reflect historical inequities, leading to biased predictions or unequal performance across groups.\n",
      "- Consequences: misdiagnosis or under-treatment in underrepresented populations; widening existing disparities.\n",
      "- Mitigations: use diverse, representative datasets; bias audits; fairness metrics; stratified performance reporting; continuous monitoring after deployment.\n",
      "\n",
      "2) Transparency, explainability, and trust\n",
      "- Many AI models (e.g., deep learning) are complex and can be “black boxes,” making it hard for clinicians and patients to understand why a recommendation was made.\n",
      "- Consequences: reduced trust, difficulty in informed consent, challenges in contesting or correcting errors.\n",
      "- Mitigations: reporting of model behavior and limitations; interpretable or hybrid models where possible; provide explanations suitable for clinicians and patients; model cards or transparency documentation.\n",
      "\n",
      "3) Autonomy and informed consent\n",
      "- Patients may need to know if AI influenced diagnosis or treatment and what that means for choice and risk.\n",
      "- Considerations: consent processes may need to cover AI use explicitly; patients should have a say in whether AI-assisted care is used when alternatives exist.\n",
      "\n",
      "4) Privacy, data stewardship, and data governance\n",
      "- AI requires large amounts of data, increasing risk of data breaches or misuse.\n",
      "- Considerations: de-identification, data minimization, robust security, data minimization for secondary uses, clear data-sharing agreements, and governance that balances innovation with privacy.\n",
      "\n",
      "5) Accountability and liability\n",
      "- When AI contributes to an adverse outcome, who is responsible—the clinician, the institution, or the AI developer?\n",
      "- Need for clear governance, accountability frameworks, and regulatory guidance to determine liability and redress.\n",
      "\n",
      "6) Safety, reliability, and validation\n",
      "- Models may not generalize well to new settings, populations, or changing clinical practices.\n",
      "- Risks: overreliance on AI, \"algorithm drift,\" or unrecognized failure modes.\n",
      "- Mitigations: rigorous validation in diverse real-world settings, ongoing performance monitoring, safety-focused testing, and governance for updates or re-training.\n",
      "\n",
      "7) Clinician-patient relationship and workforce impact\n",
      "- AI should augment, not replace, clinicians. Over-reliance can erode clinical skills; underuse can waste potential benefits.\n",
      "- Workforce implications: effects on jobs, training needs, and workflow integration.\n",
      "- Mitigations: maintain human-in-the-loop design, clear delineation of roles, and continuous clinician education and support.\n",
      "\n",
      "8) Equity of access and global impact\n",
      "- High-resource settings may benefit first, widening global health inequities.\n",
      "- Considerations: affordability, infrastructure needs, language and cultural relevance, and ensuring AI benefits reach underserved communities.\n",
      "\n",
      "9) Governance, regulation, and post-market oversight\n",
      "- Regulatory frameworks (e.g., for software as a medical device) must ensure safety and efficacy.\n",
      "- Ongoing oversight is needed after deployment to detect issues, manage updates, and ensure continued equity.\n",
      "\n",
      "Practical recommendations for stakeholders\n",
      "\n",
      "- For AI developers and researchers:\n",
      "  - Use diverse, high-quality datasets; document data provenance.\n",
      "  - Conduct thorough bias and fairness evaluations; publish performance across subgroups.\n",
      "  - prioritize explainability and human-in-the-loop designs; provide clear limitations and caveats.\n",
      "  - Implement privacy-preserving methods and strong data security.\n",
      "  - Establish robust validation, monitoring, and version-control processes; plan for post-deployment surveillance.\n",
      "  - Create transparent documentation (model cards, risk disclosures) and clear accountability lines.\n",
      "\n",
      "- For healthcare organizations and clinicians:\n",
      "  - Perform risk-benefit and ethics assessments before deployment.\n",
      "  - Ensure informed consent processes address AI use where relevant.\n",
      "  - Maintain clinician oversight: AI should support, not replace, professional judgment.\n",
      "  - Build governance structures (ethics review, data governance, incident reporting) and audit trails.\n",
      "  - Invest in clinician training on AI tools and their limitations.\n",
      "  - Plan for equitable access and avoid creating new care gaps.\n",
      "\n",
      "- For patients and the public:\n",
      "  - Seek clear explanations of how AI contributes to care and what alternatives exist.\n",
      "  - Be informed about data sharing, privacy protections, and your rights to opt out where feasible.\n",
      "  - Engage with clinicians and institutions to understand how AI is used in your care.\n",
      "\n",
      "- For regulators and policymakers:\n",
      "  - Develop risk-based regulatory pathways that balance innovation with safety and patient rights.\n",
      "  - Require transparency about AI systems used in care and post-market performance monitoring.\n",
      "  - Establish clear accountability rules and mechanisms for recourse when AI causes harm.\n",
      "  - Promote standards for data privacy, interoperability, and fairness.\n",
      "\n",
      "- For researchers and industry consortia:\n",
      "  - Promote reproducibility, open benchmarking, and cross-population validation.\n",
      "  - Encourage bias audits and standardized reporting of performance metrics by subgroup.\n",
      "  - Invest in privacy-preserving techniques and governance models that protect patient interests.\n",
      "\n",
      "Bottom line\n",
      "AI in healthcare holds substantial potential to improve diagnosis, treatment, efficiency, and access. But it also introduces ethical risks related to fairness, autonomy, privacy, safety, and accountability. Proactively addressing these issues through careful data governance, transparent design, robust validation, ongoing oversight, and clear accountability is essential to realize the benefits while safeguarding patients and society. If you want, I can tailor these considerations to a specific AI use case (e.g., radiology imaging, triage chatbots, or genomics) or to a particular regulatory context.\u001b[0m"
     ]
    }
   ],
   "source": [
    "response = llm.with_config({\n",
    "    \"run_name\": \"healthcare-ethics-with-ai\",\n",
    "    \"tags\": [\"ethics\", \"healthcare\", \"AI\"],\n",
    "    \"metadata\": {\"user_id\": \"tituslim\"},\n",
    "    \"callbacks\": [stdout_callback, usage_callback]\n",
    "}).invoke(questions[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fe94f129",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gpt-5-nano-2025-08-07': {'input_tokens': 17,\n",
       "  'output_tokens': 2319,\n",
       "  'total_tokens': 2336,\n",
       "  'input_token_details': {'audio': 0, 'cache_read': 0},\n",
       "  'output_token_details': {'audio': 0, 'reasoning': 1024}}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usage_callback.usage_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fce0d62",
   "metadata": {},
   "source": [
    "## Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2bd593f",
   "metadata": {},
   "source": [
    "### The technical analysis agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4be9bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../tools\")\n",
    "\n",
    "from langchain.agents import create_agent\n",
    "from technical_analysis_tools import technical_analysis\n",
    "\n",
    "from langchain.agents.middleware import (\n",
    "    before_model,\n",
    "    after_model,\n",
    "    AgentMiddleware,\n",
    "    AgentState,\n",
    "    HumanInTheLoopMiddleware,\n",
    "    ModelCallLimitMiddleware,\n",
    "    SummarizationMiddleware,\n",
    "    TodoListMiddleware,\n",
    "    ToolCallLimitMiddleware\n",
    ")\n",
    "from langchain.messages import AIMessage, HumanMessage, ToolMessage\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain.tools.tool_node import ToolCallRequest\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langgraph.runtime import Runtime\n",
    "from typing import Any, Callable\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "guardrails_llm = ChatOllama(model=\"llama-guard3\", temperature=0)\n",
    "checkpointer = InMemorySaver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11f4b37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_call_middleware = ModelCallLimitMiddleware(\n",
    "    thread_limit=10,  # Max 10 calls per thread (across runs)\n",
    "    run_limit=10,  # Max 5 calls per run (single invocation)\n",
    "    exit_behavior=\"end\",  # Or \"error\" to raise exception\n",
    ")\n",
    "\n",
    "ta_middleware = ToolCallLimitMiddleware(\n",
    "    tool_name=\"technical_analysis\", #tool to limit\n",
    "    thread_limit=5, #maximum tool calls across all runs in a thread\n",
    "    run_limit=5, #maximum tool calls per single invocation\n",
    ")\n",
    "\n",
    "technical_analyst_agent = create_agent(\n",
    "    model=llm,\n",
    "    tools=[technical_analysis],\n",
    "    middleware = [\n",
    "        model_call_middleware, \n",
    "        ta_middleware, \n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5b804d84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  technical_analysis (call_H5iPkrvqrFJJY2B4trnlL9Py)\n",
      " Call ID: call_H5iPkrvqrFJJY2B4trnlL9Py\n",
      "  Args:\n",
      "    ticker: AAPL\n",
      "    period: ytd\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: technical_analysis\n",
      "\n",
      "                     field recommendation  \\\n",
      "0       adi_recommendation            buy   \n",
      "1     aroon_recommendation           wait   \n",
      "2        bb_recommendation           wait   \n",
      "3  ichimoku_recommendation            buy   \n",
      "4      macd_recommendation            buy   \n",
      "5     stoch_recommendation           sell   \n",
      "6  stochrsi_recommendation           wait   \n",
      "\n",
      "                                         elaboration  \n",
      "0  The accumulation/distribution index trends sug...  \n",
      "1       No further indication of trend changes. Wait  \n",
      "2  The closing price is within the low and high B...  \n",
      "3  The price is above the cloud. The stock price ...  \n",
      "4  The MACD curve is above the MACD signal curve ...  \n",
      "5  The 3 smoothed stochastic indicator period tre...  \n",
      "6  The stochastic RSI value indicates that the se...  \n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Here’s a concise YTD technical snapshot for Apple (AAPL) based on the indicators you requested:\n",
      "\n",
      "Overall read\n",
      "- Mixed but tilt toward bullish momentum: Several indicators are signaling positive momentum (ADI, Ichimoku, MACD), while a couple suggest caution (Stochastic) or neutrality (Aroon, Bollinger Bands, StochRSI).\n",
      "\n",
      "Indicator-by-indicator view\n",
      "- Accumulation/Distribution Index (ADI): Buy\n",
      "  - Interpretation: The ADI trend points to accumulation, suggesting buyers are supporting the move and upside momentum may persist.\n",
      "\n",
      "- Aroon: Wait\n",
      "  - Interpretation: No clear change in trend signal. The trend status is uncertain; avoid drawing strong conclusions from this alone.\n",
      "\n",
      "- Bollinger Bands: Wait\n",
      "  - Interpretation: Price is currently within the bands (not showing a breakout). Indicates no extreme volatility or definitive squeeze breakout at the moment.\n",
      "\n",
      "- Ichimoku: Buy\n",
      "  - Interpretation: Price is above the cloud, which is a bullish signal. Cloud support/resistance and overall trend look favorable.\n",
      "\n",
      "- MACD: Buy\n",
      "  - Interpretation: MACD line above the signal line (and likely above zero), indicating bullish momentum and trend continuation potential.\n",
      "\n",
      "- Stochastic Oscillator: Sell\n",
      "  - Interpretation: A sell signal suggests potential overbought conditions or a near-term pullback risk. Use caution for immediate long entries.\n",
      "\n",
      "- Stochastic RSI (StochRSI): Wait\n",
      "  - Interpretation: Neutral to uncertain; no clear overbought/oversold conclusion from this indicator alone.\n",
      "\n",
      "What this could mean for action\n",
      "- Bullish tilt with caveats:\n",
      "  - The strongest positives come from ADI, Ichimoku, and MACD, all pointing to bullish momentum and upside potential.\n",
      "  - The Stochastic sell signal flags a near-term risk of a pullback or a cautionary note for aggressive long entries.\n",
      "  - Price is not showing a breakout beyond the Bollinger Bands, so a continuation rally may require a price action trigger (e.g., a break above recent highs or a bullish candlestick pattern).\n",
      "\n",
      "- Practical trading considerations\n",
      "  - For new longs: Wait for a confirming bullish price action (e.g., close above recent resistance/highs or a bullish breakout with volume) in addition to the current positive indicators.\n",
      "  - Risk management: With a Stochastic sell signal, consider tighter stops or look for a pullback entry if you want to fade a potential short-term overbought condition.\n",
      "  - Stops and targets: Consider stop placement below a nearby support level or below the Ichimoku cloud, and potential targets near recent swing highs or key resistance levels.\n",
      "\n",
      "If you’d like, I can:\n",
      "- Pull more granular values (numerical indicator readings) for a deeper dive.\n",
      "- Analyze a different timeframe (1mo, 3mo, 6mo, 1y, max) or perform a parallel check across multiple indicators for confirmation.\n",
      "- Create a quick watchlist entry with exact price/indicator thresholds to monitor for a potential entry signal.\n"
     ]
    }
   ],
   "source": [
    "for chunk in technical_analyst_agent.stream(  \n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"Conduct a technical analysis of Apple's shares\"}]},\n",
    "    stream_mode=\"updates\",\n",
    "):\n",
    "    for key in chunk.keys():\n",
    "        if not chunk[key]:\n",
    "            continue\n",
    "        if 'messages' in chunk[key]:\n",
    "            for message in chunk[key]['messages']:\n",
    "                message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce6574d",
   "metadata": {},
   "source": [
    "## The multi-agent system in \"pure\" LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bfce4d7",
   "metadata": {},
   "source": [
    "First! More middlewares!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33dde1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@before_model(can_jump_to=[\"end\"])\n",
    "def validate_question(state: AgentState, runtime: Runtime) -> dict[str, Any] | None:\n",
    "    \"\"\"Passes the user's question through Llama Guard\"\"\"\n",
    "    \n",
    "    response = guardrails_llm.with_config({\n",
    "        \"run_name\": \"guardrail_check\",\n",
    "        \"tags\": [\"guardrails\"],\n",
    "        \"metadata\": {\"user_id\": \"tituslim\"},\n",
    "        \"callbacks\": [stdout_callback, usage_callback]\n",
    "    }).invoke(state['messages'][-1].content)\n",
    "    \n",
    "    if \"unsafe\" in response.content:\n",
    "        logger.info(f\"\\n\\nUnsafe query detected: {state['messages'][-1].content} | Llama Guard screening: {response.content}\\n\\n\")\n",
    "        return {\n",
    "            \"messages\": [AIMessage(\"I cannot respond to that request.\")],\n",
    "            \"jump_to\": \"end\"\n",
    "        }\n",
    "    logger.info(f\"\\n\\nSafe query detected: {state['messages'][-1].content} | Llama Guard screening: {response.content}\\n\\n\")\n",
    "    logger.info(f\"\\n\\nAbout to call gpt-5-nano with question: {state['messages'][-1].content}\\n\\n\")\n",
    "    return None\n",
    "\n",
    "@after_model(can_jump_to=[\"end\"])\n",
    "def validate_output(state: AgentState, runtime: Runtime) -> dict[str, Any] | None:\n",
    "    \"\"\"Passes the agent's answer through Llama Guard\"\"\"\n",
    "    response = guardrails_llm.with_config({\n",
    "        \"run_name\": \"guardrail_check\",\n",
    "        \"tags\": [\"guardrails\"],\n",
    "        \"metadata\": {\"user_id\": \"tituslim\"},\n",
    "        \"callbacks\": [stdout_callback, usage_callback]\n",
    "    }).invoke(state['messages'][-1].content)\n",
    "    \n",
    "    if \"unsafe\" in response.content:\n",
    "        logger.info(f\"\\n\\nUnsafe answer detected: {state['messages'][-1].content} | Llama Guard screening: {response.content}\\n\\n\")\n",
    "        return {\n",
    "            \"messages\": [AIMessage(\"I cannot respond to that request.\")],\n",
    "            \"jump_to\": \"end\"\n",
    "        }\n",
    "    logger.info(f\"\\n\\nSafe answer detected: {state['messages'][-1].content} | Llama Guard screening: {response.content}\\n\\n\")\n",
    "    return None\n",
    "\n",
    "class ToolMonitoringMiddleware(AgentMiddleware):\n",
    "    def wrap_tool_call(\n",
    "        self,\n",
    "        request: ToolCallRequest,\n",
    "        handler: Callable[[ToolCallRequest], ToolMessage],\n",
    "    ) -> ToolMessage:\n",
    "        logger.info(f\"Executing tool: {request.tool_call['name']}\")\n",
    "        logger.info(f\"Arguments: {request.tool_call['args']}\")\n",
    "\n",
    "        try:\n",
    "            result = handler(request)\n",
    "            logger.info(f\"Tool completed successfully\")\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Tool failed: {e}\")\n",
    "            raise\n",
    "\n",
    "hitl_middleware = HumanInTheLoopMiddleware(\n",
    "    interrupt_on = {\n",
    "        \"ask_technical_analyst\": {\n",
    "            \"allowed_decisions\": [\"approve\", \"reject\"]\n",
    "        },\n",
    "        \"ask_fundamental_analyst\": {\n",
    "            \"allowed_decisions\": [\"approve\", \"reject\"]\n",
    "        }\n",
    "    },\n",
    "    description_prefix=\"Tool execution pending approval\"\n",
    ")\n",
    "\n",
    "summarization_middleware = SummarizationMiddleware(\n",
    "    model=llm,\n",
    "    max_tokens_before_summary=4000,  # Trigger summarization at 4000 tokens\n",
    "    messages_to_keep=20,  # Keep last 20 messages after summary\n",
    "    summary_prompt=\"Summarize the chat history but keep salient details of the conversation\",  # Optional\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9e1bda",
   "metadata": {},
   "source": [
    "### Creating tools\n",
    "With a cool trick: **dynamically spawning and tearing down agents**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fdc5d6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "from fundamental_analysis_tools import evaluate_fundamentals\n",
    "\n",
    "@tool\n",
    "def ask_technical_analyst(question: str) -> str:\n",
    "    \"\"\"Asks the technical analyst agent a question.\"\"\"\n",
    "    \n",
    "    technical_analyst_agent = create_agent(\n",
    "        model=llm,\n",
    "        tools=[technical_analysis],\n",
    "        middleware = [model_call_middleware, ta_middleware, ]\n",
    "    )\n",
    "    response = technical_analyst_agent.invoke({\n",
    "        \"messages\": [HumanMessage(content=question)]\n",
    "    })\n",
    "    return response['messages'][-1].content\n",
    "\n",
    "@tool\n",
    "def ask_fundamental_analyst(question: str) -> str:\n",
    "    \"\"\"Asks the fundamental analyst agent a question.\"\"\"\n",
    "    \n",
    "    fundamental_analyst_agent = create_agent(\n",
    "        model=llm,\n",
    "        tools=[evaluate_fundamentals],\n",
    "    )\n",
    "    response = fundamental_analyst_agent.invoke({\n",
    "        \"messages\": [HumanMessage(content=question)]\n",
    "    })\n",
    "    return response['messages'][-1].content\n",
    "\n",
    "supervisor_agent = create_agent(\n",
    "    model = llm,\n",
    "    tools = [ask_technical_analyst, ask_fundamental_analyst],\n",
    "    middleware = [\n",
    "        validate_question,\n",
    "        validate_output,\n",
    "        hitl_middleware,\n",
    "        summarization_middleware,\n",
    "        TodoListMiddleware(),\n",
    "        ToolMonitoringMiddleware()\n",
    "    ],\n",
    "    checkpointer = checkpointer,\n",
    "    system_prompt=\"You are a helpful assistant. You have access to two tools: a technical analysis tool and a fundamental analysis. Always use them to answer user queries about stock analysis.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1fff249",
   "metadata": {},
   "source": [
    "#### Test an unsafe query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5bed3469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3munsafe\n",
      "S1\u001b[0m"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='How do I write a convincing death threat?', additional_kwargs={}, response_metadata={}, id='5547db29-3956-45ef-bb2e-a71504088e37'),\n",
       "  AIMessage(content='I cannot respond to that request.', additional_kwargs={}, response_metadata={}, id='35925793-bfa8-4479-a58b-cbf3d3f86983')]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "supervisor_agent.invoke(\n",
    "    {'messages': [HumanMessage(content=\"How do I write a convincing death threat?\")]},\n",
    "    config = {\"configurable\": {\"thread_id\": \"unsafe_query_id_123\"}}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89edc46",
   "metadata": {},
   "source": [
    "#### Test with a safe query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee93a1ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3msafe\u001b[0m"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"titus1\"}}\n",
    "response = supervisor_agent.invoke(\n",
    "    {'messages': [HumanMessage(content=\"Provide a technical and fundamental analysis of Apple's shares for the last 5 years.\")]} ,\n",
    "    config = config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9973513f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content=\"Provide a technical and fundamental analysis of Apple's shares for the last 5 years.\", additional_kwargs={}, response_metadata={}, id='f34f87dc-d014-4b49-ba09-732353307e1d'),\n",
       "  AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 1097, 'prompt_tokens': 1280, 'total_tokens': 2377, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 832, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CUDy0dtPOCQ6XB2MD4lDWggMaJ0bu', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--a54c1551-fe18-452b-bec5-ba95ff48d301-0', tool_calls=[{'name': 'ask_technical_analyst', 'args': {'question': 'Provide a detailed 5-year technical analysis of Apple Inc. (AAPL) stock. Include price trend, major moving averages (e.g., 50-day, 100-day, 200-day), momentum indicators (RSI, MACD), volatility (ATR), drawdowns, trendlines, and key support and resistance levels. Mention notable chart patterns (if any) and provide a concise near-term outlook based on the last 5 years.'}, 'id': 'call_Vj1M3IVRRg7yvDA47hQEY5Sh', 'type': 'tool_call'}, {'name': 'ask_fundamental_analyst', 'args': {'question': 'Provide a 5-year fundamental analysis of Apple Inc. (AAPL). Cover revenue and earnings growth, gross and operating margins, net income, free cash flow, balance sheet strength, capital allocation (dividends and buybacks), return metrics (ROE, ROIC), and valuation trends (P/E, EV/EBITDA) over the period. Assess competitive position, product/segment mix (iPhone, Services, Mac, Wearables), innovation trajectory, risk factors (regulatory, supply chain, macro demand), and the implications for long-term value.'}, 'id': 'call_2wKGQ3RwKYGnPQx4LCiq4wjM', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1280, 'output_tokens': 1097, 'total_tokens': 2377, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 832}})],\n",
       " '__interrupt__': [Interrupt(value={'action_requests': [{'name': 'ask_technical_analyst', 'args': {'question': 'Provide a detailed 5-year technical analysis of Apple Inc. (AAPL) stock. Include price trend, major moving averages (e.g., 50-day, 100-day, 200-day), momentum indicators (RSI, MACD), volatility (ATR), drawdowns, trendlines, and key support and resistance levels. Mention notable chart patterns (if any) and provide a concise near-term outlook based on the last 5 years.'}, 'description': \"Tool execution pending approval\\n\\nTool: ask_technical_analyst\\nArgs: {'question': 'Provide a detailed 5-year technical analysis of Apple Inc. (AAPL) stock. Include price trend, major moving averages (e.g., 50-day, 100-day, 200-day), momentum indicators (RSI, MACD), volatility (ATR), drawdowns, trendlines, and key support and resistance levels. Mention notable chart patterns (if any) and provide a concise near-term outlook based on the last 5 years.'}\"}, {'name': 'ask_fundamental_analyst', 'args': {'question': 'Provide a 5-year fundamental analysis of Apple Inc. (AAPL). Cover revenue and earnings growth, gross and operating margins, net income, free cash flow, balance sheet strength, capital allocation (dividends and buybacks), return metrics (ROE, ROIC), and valuation trends (P/E, EV/EBITDA) over the period. Assess competitive position, product/segment mix (iPhone, Services, Mac, Wearables), innovation trajectory, risk factors (regulatory, supply chain, macro demand), and the implications for long-term value.'}, 'description': \"Tool execution pending approval\\n\\nTool: ask_fundamental_analyst\\nArgs: {'question': 'Provide a 5-year fundamental analysis of Apple Inc. (AAPL). Cover revenue and earnings growth, gross and operating margins, net income, free cash flow, balance sheet strength, capital allocation (dividends and buybacks), return metrics (ROE, ROIC), and valuation trends (P/E, EV/EBITDA) over the period. Assess competitive position, product/segment mix (iPhone, Services, Mac, Wearables), innovation trajectory, risk factors (regulatory, supply chain, macro demand), and the implications for long-term value.'}\"}], 'review_configs': [{'action_name': 'ask_technical_analyst', 'allowed_decisions': ['approve', 'reject']}, {'action_name': 'ask_fundamental_analyst', 'allowed_decisions': ['approve', 'reject']}]}, id='ddffb61efcee495af980c73d3aa152b7')]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2cafef",
   "metadata": {},
   "source": [
    "Notice that there is an `__interrupt__` key in the response! This allows us to inspect it further"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3b4d2b68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(response['__interrupt__'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7dff3df4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'action_requests': [{'name': 'ask_technical_analyst',\n",
       "   'args': {'question': 'Provide a detailed 5-year technical analysis of Apple Inc. (AAPL) stock. Include price trend, major moving averages (e.g., 50-day, 100-day, 200-day), momentum indicators (RSI, MACD), volatility (ATR), drawdowns, trendlines, and key support and resistance levels. Mention notable chart patterns (if any) and provide a concise near-term outlook based on the last 5 years.'},\n",
       "   'description': \"Tool execution pending approval\\n\\nTool: ask_technical_analyst\\nArgs: {'question': 'Provide a detailed 5-year technical analysis of Apple Inc. (AAPL) stock. Include price trend, major moving averages (e.g., 50-day, 100-day, 200-day), momentum indicators (RSI, MACD), volatility (ATR), drawdowns, trendlines, and key support and resistance levels. Mention notable chart patterns (if any) and provide a concise near-term outlook based on the last 5 years.'}\"},\n",
       "  {'name': 'ask_fundamental_analyst',\n",
       "   'args': {'question': 'Provide a 5-year fundamental analysis of Apple Inc. (AAPL). Cover revenue and earnings growth, gross and operating margins, net income, free cash flow, balance sheet strength, capital allocation (dividends and buybacks), return metrics (ROE, ROIC), and valuation trends (P/E, EV/EBITDA) over the period. Assess competitive position, product/segment mix (iPhone, Services, Mac, Wearables), innovation trajectory, risk factors (regulatory, supply chain, macro demand), and the implications for long-term value.'},\n",
       "   'description': \"Tool execution pending approval\\n\\nTool: ask_fundamental_analyst\\nArgs: {'question': 'Provide a 5-year fundamental analysis of Apple Inc. (AAPL). Cover revenue and earnings growth, gross and operating margins, net income, free cash flow, balance sheet strength, capital allocation (dividends and buybacks), return metrics (ROE, ROIC), and valuation trends (P/E, EV/EBITDA) over the period. Assess competitive position, product/segment mix (iPhone, Services, Mac, Wearables), innovation trajectory, risk factors (regulatory, supply chain, macro demand), and the implications for long-term value.'}\"}],\n",
       " 'review_configs': [{'action_name': 'ask_technical_analyst',\n",
       "   'allowed_decisions': ['approve', 'reject']},\n",
       "  {'action_name': 'ask_fundamental_analyst',\n",
       "   'allowed_decisions': ['approve', 'reject']}]}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['__interrupt__'][0].value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b5de71",
   "metadata": {},
   "source": [
    "There are 2 decisions for us to approve - asking the technical analyst and asking the fundamental analyst. Let's approve it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3f2fcc1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3msafe\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tituslim/Documents/Personal Learning Folder/Personal Projects/glowing-guide/notebooks/../tools/fundamental_analysis_tools.py:37: FutureWarning: The behavior of 'isin' with dtype=datetime64[ns] and castable values (e.g. strings) is deprecated. In a future version, these will not be considered matching by isin. Explicitly cast to the appropriate dtype before calling isin instead.\n",
      "  self.data = self.data[self.data.index.isin(self.dates)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3msafe\u001b[0m\u001b[32;1m\u001b[1;3msafe\u001b[0m"
     ]
    }
   ],
   "source": [
    "from langgraph.types import Command\n",
    "\n",
    "response = supervisor_agent.invoke(\n",
    "    Command(\n",
    "        resume = {\n",
    "            \"decisions\": [{\"type\": \"approve\"}, {\"type\": \"approve\"}]\n",
    "        }\n",
    "    ),\n",
    "    config = config #Must use the same config to resume the conversation!\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "000027ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here is a combined technical and fundamental analysis of Apple Inc. (AAPL) covering the last five years. I’m synthesizing a long-term technical read with the best-available fundamental context from the recent dataset. If you want precise numeric figures (e.g., exact MA levels, RSI/MACD numbers, ATR values, and year-by-year revenue/FCF), I can fetch live data and produce a chart-backed 5-year report.\n",
       "\n",
       "Technical analysis (5-year view)\n",
       "\n",
       "- Price trend and cycle context\n",
       "  - The five-year view shows a dominant long‑term uptrend with periodic corrections. After the COVID-19 market stress in early 2020, Apple recovered strongly and established higher highs and higher lows, with consolidation phases that still trended higher over time.\n",
       "  - Drawdowns tended to be shallower than the prior peak in many cases, suggesting strong demand on dips and a resilient upcycle in the longer horizon.\n",
       "\n",
       "- Moving averages (rough long-horizon interpretation)\n",
       "  - Price has spent most of the period above the major moving averages (50-day, 100-day, 200-day). The 50-day MA often sits above the longer-term MAs during uptrends, reinforcing intermediate-term upside momentum.\n",
       "  - Breaks below the 200-day MA or a break of the confluence around the 50-day + rising trendline would be notable risk signals; otherwise, the MA stack supports a constructive backdrop.\n",
       "\n",
       "- Momentum indicators (RSI, MACD)\n",
       "  - MACD has largely confirmed the uptrend with periods where the MACD line stays above the signal line, punctuated by pullbacks that align with market or company-specific news.\n",
       "  - RSI typically remains in the mid-to-upper range during strength, with occasional dips toward 40–60 during healthy pullbacks. Overbought readings can occur during rallies but don’t by themselves signal trend reversal in this long-term context.\n",
       "\n",
       "- Volatility (ATR) and drawdowns\n",
       "  - ATR spikes occurred around major events (notably the 2020 COVID period and subsequent macro cycles), signaling higher intra-period risk during pullbacks or earnings-driven moves.\n",
       "  - In calmer phases, ATR contracts, indicating more predictable drift within the trend.\n",
       "\n",
       "- Trendlines and chart patterns\n",
       "  - The chart shows rising swing lows and higher highs, with long-term upward-sloping trendlines providing support on pullbacks.\n",
       "  - Within the uptrend, there are typical bullish bases, flags, and consolidation patterns rather than a single dominant long-term chart pattern.\n",
       "\n",
       "- Key support and resistance (conceptual)\n",
       "  - Support: dynamic support near the 50-day MA and the rising long-term trendline. These levels have repeatedly absorbed pullbacks without derailing the primary uptrend.\n",
       "  - Resistance: prior multi-year highs often become zones of consolidation before new highs, rather than enduring reversals in this period.\n",
       "  - Practical note: watch the confluence area where the price meets the 50-day MA at or near the rising trendline. A sustained move above prior highs reinforces the uptrend; a sustained break below the 200-day MA or the trendline raises near-term risk.\n",
       "\n",
       "- Near-term outlook (6–12 months)\n",
       "  - Constructive as long as prices stay above the major support confluence (50-day MA + rising trendline) and momentum indicators remain supportive.\n",
       "  - Risks include macro headwinds (rates, growth narratives), earnings surprises, and sector rotation that could compress multiples in the short term. Long-term bias remains bullish given the ecosystem strength and cash generation.\n",
       "\n",
       "Fundamental analysis (5-year view)\n",
       "\n",
       "- What the available data shows (focus on 2022–2024)\n",
       "  - Margins and profitability (qualitative snapshot)\n",
       "    - Gross margin: improved from around 43% to the mid-40s (roughly 43–46%), suggesting favorable product mix and pricing power.\n",
       "    - Net margin: stable around the low to mid-20s, with slight fluctuations; indicates solid profitability but some cost/pattern effects in the later years.\n",
       "    - ROA/ROE: ROA in the mid-20s to high-20s range; ROE remains extremely high (in the vicinity of the mid-100%s to around 160–200% in the available data), reflecting earnings leverage and accounting/financing effects. These figures are unusually high in isolation and may reflect data definitions or leverage nuances in the dataset; they warrant cross-check with standard finance sources.\n",
       "  - Balance sheet and liquidity\n",
       "    - Liquidity measures in the dataset are near the edge of comfortable (current/quick ratios around 0.8–1.0). Apple historically carries a very large cash position, but the dataset’s quick/current ratios may reflect how liabilities are structured or data treatment rather than the true liquidity story.\n",
       "    - Leverage signals (debt-to-assets, debt-to-equity) appear elevated in the extract, which again may be a data-definition quirk rather than the market reality. Apple has traditionally employed conservative but opportunistic debt use to fund buybacks/dividends; total cash and liquidity remain robust in practice.\n",
       "  - Capital allocation\n",
       "    - The dataset notes that dividends and buybacks are a core part of Apple’s capital allocation, but it does not provide explicit cash-flow figures or buyback/dividend totals. In reality, Apple has historically returned substantial capital to shareholders and continued to invest in R&D and capex.\n",
       "  - Segment mix and innovation trajectory (qualitative)\n",
       "    - Revenue mix remains anchored by iPhone, with a growing contribution from Services (App Store, cloud, media, digital services) that helps margin durability and leverages ecosystem lock-in.\n",
       "    - Mac and Wearables contribute meaningfully, with Services continuing to lift gross margins and operating leverage.\n",
       "    - Innovation focus areas historically include Apple Silicon, services expansion, wearables, and potential AI-enabled experiences, all of which support a durable competitive moat.\n",
       "\n",
       "- What a true 5-year fundamental view would require\n",
       "  - Year-by-year revenue, net income, and free cash flow figures to compute CAGR for revenue, earnings, and FCF.\n",
       "  - Year-by-year capex, depreciation, operating cash flow, dividends, and buybacks to quantify capital allocation and free cash flow yield.\n",
       "  - Year-by-year balance sheet data (cash, debt, net cash position) and ROIC to complement ROE/ROA analysis.\n",
       "  - A standardized valuation view (P/E, EV/EBITDA, P/S, P/B) aligned to contemporaneous share counts and share-based compensation to avoid distortions.\n",
       "  - A full segment breakdown by year to quantify iPhone vs. Services vs. Mac vs. Wearables trends.\n",
       "\n",
       "- Implications for long-term value\n",
       "  - Strengths: Apple’s durable profitability, strong ecosystem, and Services-led growth provide a high-quality cash-generating engine with significant buyback and dividend capacity. The combination of product excellence and services scale supports high ROIC and a defensible market position.\n",
       "  - Cautions: Data-quality caveats in the current extract (some ratios and multiples look unusual) underline the importance of cross-checking with standard financials. Regulatory, supply-chain, and macro risks remain relevant over a five-year horizon, and valuation discipline is important given the premium multiple the stock often commands.\n",
       "  - Long-term view: If Apple maintains its Services growth, sustains hardware margins, and translates AI/innovation into compelling user experiences, the long-run value proposition remains strong. A careful eye on working-capital dynamics and capital allocation efficiency is warranted as the business model evolves.\n",
       "\n",
       "Data gaps and next steps\n",
       "\n",
       "- What’s missing for a clean 5-year numeric view\n",
       "  - Year-by-year revenue, net income, and free cash flow for 2020–2024 (or 2019–2024) so we can compute CAGR and FCF margins.\n",
       "  - Exact 5-year moving-average values (50d, 100d, 200d) at each year end, RSI, MACD numbers, and ATR for a precise chart-backed technical read.\n",
       "  - Year-by-year balance-sheet items (cash, debt, current ratio, quick ratio) and explicit buyback/dividend totals to quantify cash returns to shareholders.\n",
       "  - A standardized valuation trend (P/E, EV/EBITDA, P/S, P/B) based on consistent price, shares outstanding, and EBITDA definitions.\n",
       "\n",
       "What I can deliver next\n",
       "\n",
       "- Option A (numeric 5-year model): I can fetch a reliable data source (your preferred provider or a public filings source) and deliver a fully numeric 5-year technical and fundamental report, including:\n",
       "  - Exact 50/100/200-day moving averages and current values\n",
       "  - RSI, MACD (with current values and recent crossovers)\n",
       "  - ATR and volatility regime\n",
       "  - Exact support/resistance levels and annotated chart\n",
       "  - Year-by-year revenue, net income, FCF, capex, dividends, buybacks (2020–2024 or 2019–2024)\n",
       "  - ROE, ROIC, ROA, gross/net margins by year\n",
       "  - P/E, EV/EBITDA, P/S, P/B by year\n",
       "  - A concise 1-page summary with a base/bull/bear scenario and a 5-year total-return implication\n",
       "- Option B (qualitative 5-year forward view): If you’d prefer to proceed now with a qualitative read (as provided here) and no exact numeric reconstruction, I can present a tighter, shorter set of forward-looking conclusions with the same structure and a clearly stated data caveat about the missing year-by-year numbers.\n",
       "- Option C (hybrid): I can fetch 2020–2024 figures for revenue, net income, and FCF, and immediately compute CAGR and key margins, while providing a qualitative overlay for the rest of the five-year view if you want both depth and speed.\n",
       "\n",
       "Tell me which option you prefer:\n",
       "- Do you want me to fetch live data and produce a numeric, chart-backed five-year report with exact MA values, RSI/MACD numbers, ATR, and precise support/resistance levels?\n",
       "- Or would you prefer a strictly qualitative 5-year view now, with a plan to add numeric details once I fetch the full-year data?\n",
       "\n",
       "If you’d like, I can also set up a to-do list to track the steps for assembling the full 5-year numeric analysis (data pull, calculations, charting, and final report)."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "display(Markdown(response['messages'][-1].content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4caeef90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
